{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./common.ipynb\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_token=os.getenv('JIRA_TOKEN')\n",
    "\n",
    "if not api_token:\n",
    "    raise ValueError(\"No JIRA API token found. Check your .env file / environment variable.\")\n",
    "\n",
    "\n",
    "global logger\n",
    "logger = setup_logger(logging.INFO)\n",
    "logger.info(\"=======================================\")\n",
    "logger.info(\"Script start accumulating data from JIRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run_proj = sys.argv[1]\n",
    "run_proj ='ALL'\n",
    "\n",
    "\n",
    "partitionCnt=5\n",
    "filepath='/Users/u1002018/Library/CloudStorage/OneDrive-SharedLibraries-FootLocker/Global Technology Services - DASH Doc Library/LaborCap_TEST/'\n",
    "\n",
    "# filepath='../output/TimeSheet'\n",
    "importfile='/Users/u1002018/Library/CloudStorage/OneDrive-SharedLibraries-FootLocker/Global Technology Services - DASH Doc Library/AllProjects/transition_history_Story.csv'\n",
    "\n",
    "issueLists = [\n",
    "            # {'issueType':\"Portfolio Initiative\",'partitionCnt':3},\n",
    "            # {'issueType':\"Product Initiative\", 'partitionCnt':3},\n",
    "            # {'issueType':\"Epic\",'partitionCnt':partitionCnt},\n",
    "            {'issueType':\"Story\",'partitionCnt':partitionCnt}\n",
    "            ]\n",
    "             \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jira ID \n",
    "# Name\n",
    "# Planview Portfolio ID\n",
    "# Work Description\n",
    "# IssueType\n",
    "# Work State\n",
    "def portoFolioDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.issuetype.name',\n",
    "                             'fields.status.name','fields.customfield_32307'\n",
    "                         #  'fields.description',\n",
    "        ]).rename(columns={\n",
    "        'key':'Key',\n",
    "        'fields.summary':'Summary',\n",
    "        'fields.customfield_32307':'Planview Portfolio ID',\n",
    "        # 'fields.description':'Work Description',\n",
    "        'fields.issuetype.name':'IssueType',\n",
    "        'fields.status.name':'Status'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name\n",
    "# ParentLink\n",
    "# Work Description\n",
    "# Jira ID\n",
    "# IssueType\n",
    "# Start date\n",
    "# End date\n",
    "# Work State\n",
    "def productInitDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.customfield_12823',\n",
    "                             'fields.issuetype.name','fields.status.name',\n",
    "                            #  'fields.description',\n",
    "                            'fields.project.name'\n",
    "                            ]).rename(columns={\n",
    "                            'key':'Key',\n",
    "                            'fields.summary':'Summary',\n",
    "                            'fields.customfield_12823': 'ParentLink',\n",
    "                            # 'fields.description':'Work Description',\n",
    "                            'fields.issuetype.name':'IssueType',\n",
    "                            'fields.status.name':'Status', \n",
    "                            'fields.project.name':'ProjectName'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name ✅\n",
    "# ParentLink ✅\n",
    "# Work Description ❌\n",
    "# Jira ID ✅\n",
    "# IssueType ✅\n",
    "# Start date ✅\n",
    "# End date ✅\n",
    "# Banner ✅\n",
    "# Region ✅\n",
    "# T-shirt Size ✅\n",
    "# Epic Work Type ✅\n",
    "# Work State ✅\n",
    "# In-Progress DateDate ⏳\n",
    "# Completed Date ⏳\n",
    "def epicDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.customfield_12823',\n",
    "                             'fields.issuetype.name','fields.status.name','fields.customfield_12305',\n",
    "                             'fields.customfield_31400.value', 'fields.project.name', \n",
    "                             'fields.customfield_13800', 'fields.customfield_13801','fields.project.key','fields.customfield_10207.value',\n",
    "                             'fields.customfield_17210','fields.customfield_17211'\n",
    "                            #  'fields.description',\n",
    "        ]).rename(columns={\n",
    "        'fields.summary':'Summary',\n",
    "        'key':'Key',\n",
    "        'fields.customfield_12823': 'ParentLink',\n",
    "        # 'fields.description':'Work Description',\n",
    "        'fields.customfield_12305':'Banner',\n",
    "        'fields.issuetype.name':'IssueType',\n",
    "        'fields.status.name':'Status',\n",
    "        'fields.project.name':'ProjectName',\n",
    "        'fields.project.key':'ProjectKey',\n",
    "        'fields.customfield_31400.value': 'Epic Type',\n",
    "        'fields.customfield_13800': 'Target start',\n",
    "        'fields.customfield_13801': 'Target end',\n",
    "        'fields.customfield_10207.value':'T-Shirt size',\n",
    "        'fields.customfield_17210':'Affected Banners',\n",
    "        'fields.customfield_17211':'Affected Geographies'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name ✅\n",
    "# ParentLink ✅\n",
    "# Work Description ❌\n",
    "# Jira ID ✅\n",
    "# IssueType ✅\n",
    "# Story Estimate ✅\n",
    "# Story Work Type ✅\n",
    "# Work State ✅\n",
    "# In-Progress Date ✅\n",
    "# Completed Date ✅\n",
    "# Jira Project Name ✅\n",
    "def StoryDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.customfield_10006',\n",
    "                             'fields.customfield_10002',\n",
    "                             'fields.issuetype.name','fields.status.name',\n",
    "                             'fields.project.name','fields.customfield_31800.value','fields.project.key'\n",
    "         #  'fields.description',\n",
    "        ]).rename(columns={\n",
    "        'fields.summary':'Summary',\n",
    "        'fields.customfield_10006': 'ParentLink', #Epic Link\n",
    "      # 'fields.description':'Work Description',\n",
    "        'fields.customfield_31800.value':'Story Type',\n",
    "        'key':'Key',\n",
    "         'fields.issuetype.name':'IssueType',\n",
    "        'fields.customfield_10002':'StoryPoint',\n",
    "        'fields.status.name':'Status',\n",
    "        'fields.project.name':'ProjectName',\n",
    "        'fields.project.key':'ProjectKey',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDates(key,state):\n",
    "    dates=''\n",
    "    filterdata = importTransactionFile[importTransactionFile['key']==key]\n",
    "    if state == 'close':    \n",
    "     state= filterdata[filterdata['to'].isin(close_state)]\n",
    "    else:\n",
    "     state= filterdata[filterdata['to'].isin(development_state)]\n",
    "    \n",
    "    if state is not None and not state.empty:\n",
    "        dates= state['created_at'].values[0]\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(dataframe, issueType):\n",
    "    if dataframe is not None and not dataframe.empty:\n",
    "       if issueType == 'Portfolio Initiative':\n",
    "         dataframe = portoFolioDataframe(dataframe)\n",
    "       elif issueType == 'Product Initiative':\n",
    "         dataframe = productInitDataframe(dataframe)\n",
    "       elif issueType == 'Epic':\n",
    "          dataframe = epicDataframe(dataframe)\n",
    "          dataframe['Affected Banners']=dataframe['Affected Banners'].apply(lambda x: getBaselineLst(x) )\n",
    "          dataframe['Affected Geographies']=dataframe['Affected Geographies'].apply(lambda x: getBaselineLst(x) )\n",
    "          # dataframe['ProjectName'] = dataframe['ProjectName'].str.replace('&', '%26')\n",
    "          header = list(dataframe.columns)\n",
    "          \n",
    "          if 'T-Shirt size' not in header:\n",
    "            dataframe['T-Shirt size'] =\"\"\n",
    "            # dataframe = dataframe.reindex(columns=header, fill_value=\"\")\n",
    "          \n",
    "          if 'Epic Type' not in header:\n",
    "            dataframe['Epic Type'] =\"\"\n",
    "\n",
    "       elif issueType == 'Story':\n",
    "          dataframe = StoryDataframe(dataframe)\n",
    "          dataframe['In-Progress Date'] = dataframe['Key'].apply(lambda x: getDates(x,'inProgress'))\n",
    "          dataframe['Completed Date'] = dataframe['Key'].apply(lambda x: getDates(x,'close'))\n",
    "          # dataframe['ProjectName'] = dataframe['ProjectName'].str.replace('&', '%26')\n",
    "\n",
    "          # header = list(dataframe.columns)\n",
    "          # if 'In-Progress Date' not in header:\n",
    "          #   dataframe['In-Progress Date'] =\"\"\n",
    "          # if 'Completed Date' not in header:\n",
    "          #   dataframe['Completed Date'] =\"\"\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch( project, issueType):\n",
    "    global fetch_df \n",
    "    logger.info(f\"Fetch {issueType}...\")\n",
    "\n",
    "    # if issueType == 'Story':\n",
    "    #     attribute =' &expand=projects.issuetypes.fields,changelog'\n",
    "    # else:\n",
    "    attribute =' '\n",
    "    development_state_Lst = '\", \"'.join(development_state)\n",
    "    deployment_state_Lst = '\", \"'.join(deployment_state)\n",
    "    qa_state_Lst = '\", \"'.join(qa_state)\n",
    "\n",
    "    liststr = '\"{0}\",\"{1}\",\"{2}\"'.format(development_state_Lst, deployment_state_Lst,qa_state_Lst )\n",
    "    \n",
    "\n",
    "    searchQry=f'?jql= project in ({project}) and issueType=\"{issueType}\" and status in ({liststr}) and updated > -30d'\n",
    "\n",
    "    # if cond_flg == True: \n",
    "    #     searchQry=f\"{searchQry} and status not in (Cancelled, Done)  {attribute}\"\n",
    "    # else:\n",
    "    searchQry=f\"{searchQry} {attribute}\"\n",
    "\n",
    "    fetch_df = getDataSet(searchQry, project, issueType, api_token )\n",
    "\n",
    "    return data_clean(fetch_df,issueType )    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChangeLog(element):\n",
    "    changelog_Rec = [] \n",
    "    for history in element:\n",
    "        created_at = history.get('created',None)\n",
    "        for item in history['items']:\n",
    "            if item['field'] =='status' :\n",
    "                changelog_Rec.append({\n",
    "                    'created_at': created_at,\n",
    "                    'field': item['field'],\n",
    "                    'from': item['fromString'],\n",
    "                    'to': item['toString'],\n",
    "                })\n",
    "    return changelog_Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean folder\n",
    "csv_files = Path(filepath).glob(\"*_working.csv\")\n",
    "for file in csv_files:\n",
    "    filename=file.name\n",
    "    os.remove(os.path.join(filepath, filename))\n",
    "\n",
    "global importTransactionFile \n",
    "importTransactionFile = pd.read_csv(importfile)\n",
    "\n",
    "# strings =pd.Series([\"PCR\"])\n",
    "strings = projectList(api_token)\n",
    "\n",
    "for issueList in issueLists:\n",
    "    split_string_list = split_list(strings, issueList['partitionCnt'])\n",
    "    filtered_list = [series for series in split_string_list if not series.empty]\n",
    "    for partition in filtered_list:\n",
    "        logger.warning(f\"processing %s - %s\",partition.values[0],issueList['issueType'])\n",
    "\n",
    "        df=fetch(', '.join(['\"{}\"'.format(value) for value in partition]),issueList['issueType'])\n",
    "        if df is not None and not df.empty:\n",
    "            try:     \n",
    "                    output_path = os.path.join(filepath, f\"{issueList['issueType']}_working.csv\")            \n",
    "                    # df.to_csv(output_path ,mode='a', header=not os.path.exists(output_path), index=False)\n",
    "                    append_to_csv(df,output_path)\n",
    "            except Exception as e:  \n",
    "                logger.error(f\"Failed to upload files to {filepath}: {e}\")\n",
    "                pass\n",
    "                \n",
    "            logger.info(\"Move working files to current files\")\n",
    "            # Delete the old DataFrame \n",
    "            del(df)\n",
    "\n",
    "            # Perform garbage collection                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "            gc.collect()\n",
    "            # break\n",
    "    clean_folder(filepath,\"_working.csv\")\n",
    "\n",
    "del(importTransactionFile)\n",
    "# Perform garbage collection                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "gc.collect()\n",
    "logger.warning(f\"Script ended accumulating data from JIRA \")\n",
    "logger.warning(\"=======================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4 ('development')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fb6657aaf366e700473b4691a0218895a79fd82ea30347f6976080edd370586"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
