{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./common.ipynb\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_token=os.getenv('JIRA_TOKEN')\n",
    "\n",
    "if not api_token:\n",
    "    raise ValueError(\"No JIRA API token found. Check your .env file / environment variable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run_proj = sys.argv[1]\n",
    "run_proj ='ALL'\n",
    "\n",
    "\n",
    "partitionCnt=5\n",
    "# filepath='/Users/u1002018/Library/CloudStorage/OneDrive-SharedLibraries-FootLocker/Global Technology Services - DASH Doc Library/Timesheet/'\n",
    "\n",
    "filepath='../output/TimeSheet'\n",
    "\n",
    "discovery_state = [\"created\",\n",
    "    \"New\",\n",
    "    \"Ready for Development\",\n",
    "    \"PO Validation\",\n",
    "    \"PO Grooming\",\n",
    "    \"Ready for Refinement\",\n",
    "    \"To Do\",\n",
    "    \"FA Grooming\",\n",
    "    \"Open\",\n",
    "    \"In Planning\",\n",
    "    \"Dev Grooming/Estimation\",\n",
    "    \"Technical Grooming\",\n",
    "    \"Deferred\",\n",
    "    \"Backlog\",\n",
    "    \"Scrum of Scrums Items\",\n",
    "    \"Refinement\",\n",
    "    \"Ready for Assignment\",\n",
    "    \"Selected for Development\",\n",
    "    \"M Editorial Request Drafts\",\n",
    "    \"Pending Evaluation\",\n",
    "    \"Add to Backlog\",\n",
    "    \"Prioritized\",\n",
    "    \"Intake\",\n",
    "    \"Request Acknowledged\",\n",
    "    \"Design\",\n",
    "    \"Intake Request\",\n",
    "    \"Initiated\",\n",
    "    \"Assigned\",\n",
    "    \"Triage\",\n",
    "    \"Functional Grooming\",\n",
    "    \"Style Review\",\n",
    "    \"Acceptance / Review\",\n",
    "    \"Hold for Dependencies\",\n",
    "    \"Awaiting Requirements\",\n",
    "    \"Action Needed\",\n",
    "    \"On-Hold\",\n",
    "    \"Ready For Deployment\",\n",
    "    \"Grooming\",\n",
    "    \"Analysis in Progress\",\n",
    "    \"Waiting for Information\",\n",
    "    \"M Editorial To Do\",\n",
    "    \"M Editorial In Progress\",\n",
    "    \"S&D Request Drafts\",\n",
    "    \"S&D To Do\",\n",
    "    \"SM Backlog\",\n",
    "    \"Discovery Gate Prep\",\n",
    "    \"CAR Submitted\",\n",
    "    \"Ready for Requirements\",\n",
    "    \"Req-Arch in Progress\",\n",
    "    \"Ready for Estimation\",\n",
    "    \"Ready for Planning\",\n",
    "    \"Ready for Review\",\n",
    "    \"Planning in Progress\",\n",
    "    \"Architect Review\",\n",
    "    \"New Project Requests\",\n",
    "    \"Approved Project Backlog\",\n",
    "    \"Discovery\",\n",
    "    \"Architect Review Dependencies\",\n",
    "    \"JDAP Ready\",\n",
    "    \"Cleaned Up (Temporary)\",\n",
    "    \"With Vendor\",\n",
    "    \"S&D Stakeholder Review\",\n",
    "    \"Ready for test\",\n",
    "    \"First Priority\",\n",
    "    \"Results Ready\",\n",
    "    \"Analysis\",\n",
    "    \"ToDo\",\n",
    "    \"Ready\",\n",
    "    \"Integration Test\",\n",
    "    \"Approved & Prioritized\",\n",
    "    \"Discussion/Review\",\n",
    "    \"Pending\",\n",
    "    \"Ready to Work\",\n",
    "    \"Functional\",\n",
    "    \"NEEDS MORE INFO\",\n",
    "    \"IN UX/UI\",\n",
    "    \"Needs Approval\",\n",
    "    \"Assessing\",\n",
    "    \"Submitted for Assessment\",\n",
    "    \"Pending Decision\",\n",
    "    \"Decided\",\n",
    "    \"Ready for Dev\",\n",
    "    \"Action Required\",\n",
    "    \"Submitted\",\n",
    "    \"Planning\",\n",
    "    \"Measurement Requirements\",\n",
    "    \"UX Design\",\n",
    "    \"Stakeholder Review\",\n",
    "    \"Stakeholder Kickoff\",\n",
    "    \"Research\",\n",
    "    \"Analyze Results\",\n",
    "    \"Reviewed\",\n",
    "    \"Requirements\",\n",
    "    \"On Hold - To Do\",\n",
    "    \"Ice Box\",\n",
    "    \"Ready for Deploy\",\n",
    "    \"TO-DO\",\n",
    "    \"On Hold/Ready\",\n",
    "    \"Reseach\",\n",
    "    \"Wireframes To Do\",\n",
    "    \"New Requests\",\n",
    "    \"Approved for Estimation\",\n",
    "    \"Estimated / Ready for Review\",\n",
    "    \"Budgeted\",\n",
    "    \"Tech Feasibility\",\n",
    "    \"Product Review\",\n",
    "    \"Ready For Approval\",\n",
    "    \"New Request\",\n",
    "    \"Defect Created\",\n",
    "    \"Documentation and Tie-off\",\n",
    "    \"Business Case Review\",\n",
    "    \"Proposed\",\n",
    "    \"Under Evaluation\",\n",
    "    \"Under Review\",\n",
    "    \"Request Drafts\",\n",
    "    \"Parked for dependency\",\n",
    "    \"Parked\",\n",
    "    \"On Hold by FL\",\n",
    "    \"Begin\",\n",
    "    \"Concept\",\n",
    "    \"Change in Requirements\",\n",
    "    \"Ready For SNUG Review\",\n",
    "    \"Waiting Approval\",\n",
    "    \"Pending Acceptance Criteria\",\n",
    "    \"Wishlist\",\n",
    "    \"Approved Projects\",\n",
    "    \"Epics\",\n",
    "    \"Delayed\",\n",
    "    \"Not Started\",\n",
    "    \"Drafting\",\n",
    "    \"Pending PO Review\",\n",
    "    \"PO Acceptance\",\n",
    "    \"Rework\",\n",
    "    \"Ready for Implementation\",\n",
    "    \"SE Backlog\",\n",
    "    \"In UX/UI Review\",\n",
    "    \"Planning / Requirements\",\n",
    "    \"Ready for Dev Grooming & Estimation\",\n",
    "    \"Scoped\",\n",
    "    \"Ready to Diagnose\",\n",
    "    \"Waiting Feedback\",\n",
    "    \"To be reviewed\",\n",
    "    \"Board Review\",\n",
    "    \"Business Review\",\n",
    "    \"Wireframe IP\",\n",
    "    \"Mockup To Do\",\n",
    "    \"Wire Frame Needs Revision\",\n",
    "    \"Estimation\",\n",
    "    \"In Progress - UI\",\n",
    "    \"Priority List\",\n",
    "    \"Priority List - Ready for UI\",\n",
    "    \"UX\",\n",
    "    \"UX - Prioritized\",\n",
    "    \"PO - Need More Information\",\n",
    "    \"UX - In Progress\",\n",
    "    \"UX - On Hold (Waiting for Peer Review)\",\n",
    "    \"UX - Progress\",\n",
    "    \"PO - On Hold\",\n",
    "    \"Copy - In Progress\",\n",
    "    \"UI - Prioritized\",\n",
    "    \"PO - Unprioritized\",\n",
    "    \"Copy - Prioritized\",\n",
    "    \"UI-In Progress\",\n",
    "    \"UX - On Hold (Waiting for Results)\",\n",
    "    \"UX - On Hold (Waiting for Deploy)\",\n",
    "    \"UI - Ready for Style Review\",\n",
    "    \"In Progress - UX\",\n",
    "    \"Needs Approval - PO\",\n",
    "    \"UI - Needs Approval\",\n",
    "    \"On Hold - PO\",\n",
    "    \"Handed Off - Awaiting Dev\",\n",
    "    \"Prioritized - UXD\",\n",
    "    \"Design Idea\",\n",
    "    \"Product Owner / Stakeholder Review\",\n",
    "    \"Research Idea\",\n",
    "    \"Verification\",\n",
    "    \"WorkflowState\"]\n",
    "\n",
    "development_state = [\"In Development\",\n",
    "    \"Code Review\",\n",
    "    \"On Hold\",\n",
    "    \"In Progress\",\n",
    "    \"Dev Blocked\",\n",
    "    \"Deploy to Staging\",\n",
    "    \"Dev Review\",\n",
    "    \"Blocked\",\n",
    "    \"Dev - In Progress\",\n",
    "    \"Dev Complete\",\n",
    "    \"Ready for Stage\",\n",
    "    \"Reopened\",\n",
    "    \"Build\",\n",
    "    \"In Review\",\n",
    "    \"Testing\",\n",
    "    \"Review\",\n",
    "    \"Work in Progress\",\n",
    "    \"Dev In Progress\",\n",
    "    \"Dev Complete-Pull Request\",\n",
    "    \"Development\",\n",
    "    \"S&D In Progress\",\n",
    "    \"S&D Blocked\",\n",
    "    \"Solution Review\",\n",
    "    \"Peer Review\",\n",
    "    \"Workaround\",\n",
    "    \"Needs Review\",\n",
    "    \"UA Review\",\n",
    "    \"Merge Request\",\n",
    "    \"Ready for Code Review\",\n",
    "    \"Approval Needed\",\n",
    "    \"PO Approval\",\n",
    "    \"Reopen\",\n",
    "    \"Ready for PR\",\n",
    "    \"Sprint Test\",\n",
    "    \"Demo\",\n",
    "    \"Remedy In Progress\",\n",
    "    \"In Design\",\n",
    "    \"Staged\",\n",
    "    \"Development in Progress\",\n",
    "    \"Merged\",\n",
    "    \"Reivew\",\n",
    "    \"In Code Review\",\n",
    "    \"Needs Style Review\",\n",
    "    \"Develop\",\n",
    "    \"Working\",\n",
    "    \"Style/Code Review\",\n",
    "    \"Dev Done\",\n",
    "    \"Pull Request Review\",\n",
    "    \"Executing\",\n",
    "    \"Needs Revision\",\n",
    "    \"Active\",\n",
    "    \"Wireframe Review\",\n",
    "    \"Mockup IP\",\n",
    "    \"Mockup Review\",\n",
    "    \"PO - Needs Approval\"]\n",
    "\n",
    "deployment_state = [\"Monitoring\",\n",
    "    \"Production Review\",\n",
    "    \"Ready for Prod\",\n",
    "    \"Deployed\",\n",
    "    \"Deploy\",\n",
    "    \"Validate/Verify\",\n",
    "    \"S&D Complete\",\n",
    "    \"Deployed to Production\",\n",
    "    \"Deploying Increments\",\n",
    "    \"Approved\",\n",
    "    \"Validation\",\n",
    "    \"Ready to Deploy\",\n",
    "    \"Reporter Approval\",\n",
    "    \"Implemented\",\n",
    "    \"Production\",\n",
    "    \"CR Submitted\",\n",
    "    \"Deploy to Production\",\n",
    "    \"In Production\",\n",
    "    \"Post-Production\",\n",
    "    \"Validation Complete\",\n",
    "    \"Deployed to Prod\",\n",
    "    \"Staged for Deploy\",\n",
    "    \"Released Live\",\n",
    "    \"Not a Bug\",\n",
    "    \"Ready for Production\", \n",
    "    \"Deploy to Prod\"]\n",
    "\n",
    "cancel_state = [\"Closed - Not Doing\",\n",
    "    \"Duplicate\",\n",
    "    \"Closed - No Deploy\",\n",
    "    \"Denied\",\n",
    "    \"Canceled\",\n",
    "    \"Rejected\",\n",
    "    \"Cancel\",\n",
    "    \"Cancelled\",\n",
    "    \"Not Approved / Out of Scope\",\n",
    "    \"Invalid\",\n",
    "    \"Failed\",\n",
    "    \"Closed - Inactivity\",\n",
    "    \"Closed - Duplicate\"]\n",
    "\n",
    "qa_state =[\"QA Testing\",\n",
    "    \"Future Test Cases\",\n",
    "    \"Deploy to Test\",\n",
    "    \"Deploy to UAT\",\n",
    "    \"QA (UAT)\",\n",
    "    \"QA Blocked\",\n",
    "    \"QA (Test)\",\n",
    "    \"Dev Complete / Deploy to Test\",\n",
    "    \"QA (Staging)\",\n",
    "    \"QA (Prod)\",\n",
    "    \"UA (Test)\",\n",
    "    \"SIT\",\n",
    "    \"Ready for QA\",\n",
    "    \"QA In Progress\",\n",
    "    \"Ready for UAT\",\n",
    "    \"QA Staging\",\n",
    "    \"In QA\",\n",
    "    \"UAT - In Progress\",\n",
    "    \"In Testing\",\n",
    "    \"QA\",\n",
    "    \"UAT\",\n",
    "    \"Test\",\n",
    "    \"Testing / Integration (Test)\",\n",
    "    \"Deploy to QA\",\n",
    "    \"QA - In Progress\",\n",
    "    \"UAT tesing\",\n",
    "    \"test1\",\n",
    "    \"Testing in UAT\",\n",
    "    \"Ready for Testing\",\n",
    "    \"UAT Validation\",\n",
    "    \"UAT - Testing\",\n",
    "    \"Dev QA\",\n",
    "    \"QA Automation\",\n",
    "    \"QA Icebox\",\n",
    "    \"Quality Assurance\",\n",
    "    \"Deployed to UAT\",\n",
    "    \"User Acceptance Testing\",\n",
    "    \"UAT - In Review\",\n",
    "    \"To Be Tested\",\n",
    "    \"Sandbox\",\n",
    "    \"UAT - Complete\",\n",
    "    \"Stores UAT\",\n",
    "    \"QA / Testing\"]\n",
    "\n",
    "close_state = [\"Closed\",\n",
    "    \"Complete\",\n",
    "    \"Done\",\n",
    "    \"Resolved\",\n",
    "    \"Pass\",\n",
    "    \"Fixed\",\n",
    "    \"Closed - Pending Review\",\n",
    "    \"Archived\",\n",
    "    \"Archive\",\n",
    "    \"Completed\",\n",
    "    \"Completed - Change(s) Made\",\n",
    "    \"Closed - Archive\"]\n",
    "\n",
    "issueLists = [\n",
    "            {'issueType':\"Portfolio Initiative\",'partitionCnt':1},\n",
    "            {'issueType':\"Product Initiative\", 'partitionCnt':1 },\n",
    "            {'issueType':\"Epic\",'partitionCnt':partitionCnt},\n",
    "            {'issueType':\"Story\",'partitionCnt':partitionCnt}\n",
    "            ]\n",
    "             \n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jira ID \n",
    "# Name\n",
    "# Planview Portfolio ID\n",
    "# Work Description\n",
    "# IssueType\n",
    "# Work State\n",
    "def portoFolioDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.issuetype.name','fields.status.name'\n",
    "         #  'fields.description',\n",
    "        ]).rename(columns={\n",
    "        'key':'JiraID',\n",
    "        'fields.summary':'Name',\n",
    "        # 'fields.description':'Work Description',\n",
    "        'fields.issuetype.name':'IssueType',\n",
    "        'fields.status.name':'Work State'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name\n",
    "# ParentLink\n",
    "# Work Description\n",
    "# Jira ID\n",
    "# IssueType\n",
    "# Start date\n",
    "# End date\n",
    "# Work State\n",
    "def productInitDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.customfield_12823',\n",
    "                             'fields.issuetype.name','fields.status.name'\n",
    "                            #  'fields.description',\n",
    "                            ]).rename(columns={\n",
    "                            'key':'JiraID',\n",
    "                            'fields.summary':'Name',\n",
    "                            'fields.customfield_12823': 'ParentLink',\n",
    "                            # 'fields.description':'Work Description',\n",
    "                            'fields.issuetype.name':'IssueType',\n",
    "                            'fields.status.name':'Work State'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name\n",
    "# ParentLink\n",
    "# Work Description\n",
    "# Jira ID\n",
    "# IssueType\n",
    "# Start date\n",
    "# End date\n",
    "# Banner\n",
    "# Region\n",
    "# T-shirt Size\n",
    "# Epic Work Type\n",
    "# Work State\n",
    "# In-Progress Date\n",
    "# Completed Date\n",
    "def EpicDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.customfield_12823',\n",
    "                             'fields.issuetype.name','fields.status.name'\n",
    "         #  'fields.description',\n",
    "        ]).rename(columns={\n",
    "        'fields.summary':'Name',\n",
    "        'key':'JiraID',\n",
    "        'fields.customfield_12823': 'ParentLink',\n",
    "        # 'fields.description':'Work Description',\n",
    "        'fields.issuetype.name':'IssueType',\n",
    "        'fields.status.name':'Work State'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name\n",
    "# ParentLink\n",
    "# Work Description\n",
    "# Jira ID\n",
    "# IssueType\n",
    "# Story Estimate\n",
    "# Story Work Type\n",
    "# Work State\n",
    "# In-Progress Date\n",
    "# Completed Date\n",
    "# Jira Project Name\n",
    "def StoryDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.customfield_12823',\n",
    "                             'fields.customfield_10002',\n",
    "                             'fields.issuetype.name','fields.status.name',\n",
    "                             'fields.project.name',\n",
    "         #  'fields.description',\n",
    "        ]).rename(columns={\n",
    "        'fields.summary':'Name',\n",
    "        'fields.customfield_12823': 'ParentLink',\n",
    "      # 'fields.description':'Work Description',\n",
    "        'key':'JiraID',\n",
    "         'fields.issuetype.name':'IssueType',\n",
    "        'fields.customfield_10002':'StoryPoint',\n",
    "        'fields.status.name':'Work State',\n",
    "        'fields.project.name':'projectName'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "global logger\n",
    "logger = setup_logger()\n",
    "logger.info(\"=======================================\")\n",
    "logger.info(\"Script start accumulating data from JIRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(dataframe, issueType):\n",
    "    if dataframe is not None and not dataframe.empty:\n",
    "       if issueType == 'Portfolio Initiative':\n",
    "         dataframe = portoFolioDataframe(dataframe)\n",
    "       elif issueType == 'Product Initiative':\n",
    "         dataframe = productInitDataframe(dataframe)\n",
    "       elif issueType == 'Epic':\n",
    "          dataframe = EpicDataframe(dataframe)\n",
    "       elif issueType == 'Story':\n",
    "          dataframe = StoryDataframe(dataframe)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch( project, issueType):\n",
    "    global fetch_df \n",
    "    logger.info(f\"Fetch {issueType}...\")\n",
    "\n",
    "    # if issueType == 'Story':\n",
    "    #     attribute =' &expand=projects.issuetypes.fields,changelog'\n",
    "    # else:\n",
    "    attribute =' '\n",
    "\n",
    "    searchQry=f'?jql= project in ({project}) and issueType=\"{issueType}\" and updated > startOfMonth(-11)'\n",
    "\n",
    "    # if cond_flg == True: \n",
    "    #     searchQry=f\"{searchQry} and status not in (Cancelled, Done)  {attribute}\"\n",
    "    # else:\n",
    "    searchQry=f\"{searchQry} {attribute}\"\n",
    "\n",
    "    fetch_df = getDataSet(searchQry, project, issueType, api_token )\n",
    "\n",
    "    return data_clean(fetch_df,issueType )    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChangeLog(element):\n",
    "    changelog_Rec = [] \n",
    "    for history in element:\n",
    "        created_at = history.get('created',None)\n",
    "        for item in history['items']:\n",
    "            if item['field'] =='status' :\n",
    "                changelog_Rec.append({\n",
    "                    'created_at': created_at,\n",
    "                    'field': item['field'],\n",
    "                    'from': item['fromString'],\n",
    "                    'to': item['toString'],\n",
    "                })\n",
    "    return changelog_Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(lst, n):\n",
    "    \"\"\"Splits a list into n approximately equal parts.\"\"\"\n",
    "    k, m = divmod(len(lst), n)\n",
    "    \n",
    "    return [lst[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_timedelta(td):\n",
    "    \"\"\"Formats a timedelta object to 'day.hours:min:sec' format.\"\"\"\n",
    "\n",
    "    seconds = td.total_seconds()\n",
    "    days, seconds = divmod(seconds, 86400)\n",
    "    hours, seconds = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "\n",
    "    return f\"{int(days)}.{int(hours):02}:{int(minutes):02}:{int(seconds):02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCycleTime(l_Df):\n",
    "    cycleTime = {}\n",
    "    for index, row in l_Df.iterrows():\n",
    "        # display(row)\n",
    "        _status_change = pd.json_normalize(row['Changelog_Rec'])\n",
    "        if len(_status_change) > 0:\n",
    "            logger.debug(row['Status'])\n",
    "            if (row['Status'] not in close_state):\n",
    "                # Get the current time in UTC\n",
    "                now_utc = datetime.now(pytz.utc)\n",
    "                # Convert to Eastern Time\n",
    "                eastern = pytz.timezone('US/Eastern')\n",
    "                now_est = now_utc.astimezone(eastern)\n",
    "                new_node = {\n",
    "                            'created_at': now_est.strftime('%Y-%m-%dT%H:%M:%S.%f%z'),\n",
    "                             'field': 'status',\n",
    "                             'from': row['Status'],\n",
    "                             'to' : 'Active'\n",
    "                            #  'proj'=row['projectKey'],\n",
    "                            #  'key'=row['key']\n",
    "\n",
    "                            }\n",
    "                _status_change.loc[len(_status_change)] = new_node\n",
    "\n",
    "            newCreate_node = {\n",
    "                        # 'created_at': row['created_ts'].to_list()[0], \n",
    "                            'created_at': row['created_ts'],\n",
    "                            'field': 'status',\n",
    "                            'from': 'created',\n",
    "                            'to' : 'WorkflowState'\n",
    "                            # 'proj'=row['projectKey'],\n",
    "                            # 'key'=row['key']\n",
    "                        }\n",
    "\n",
    "            _status_change.loc[len(_status_change)] = newCreate_node   \n",
    "            _status_change.sort_values(by=['created_at'],inplace=True)\n",
    "            _status_change['created_at']= pd.to_datetime(_status_change['created_at'])\n",
    "            _status_change['time_diff'] = _status_change['created_at'].diff()\n",
    "\n",
    "\n",
    "\n",
    "            row['CT_leadTime'] = format_timedelta(_status_change['time_diff'].sum())\n",
    "\n",
    "            row['CT_discovery'] = format_timedelta(_status_change[_status_change['to'].isin( discovery_state )]['time_diff'].sum())\n",
    "            \n",
    "            row['CT_development'] = format_timedelta(_status_change[_status_change['to'].isin( development_state)]['time_diff'].sum())                                        \n",
    "            row['CT_deployment'] = format_timedelta(_status_change[_status_change['to'].isin(deployment_state)]['time_diff'].sum())\n",
    "            row['CT_cancelled'] = format_timedelta(_status_change[_status_change['to'].isin(cancel_state )]['time_diff'].sum())   \n",
    "            row['CT_qa'] = format_timedelta(_status_change[_status_change['to'].isin(qa_state)]['time_diff'].sum())\n",
    "\n",
    "            \n",
    "            _status_change['created_at'] = pd.to_datetime(_status_change['created_at'],utc=True)\n",
    "            _status_change['created_at'] = _status_change['created_at'].dt.date\n",
    "            _status_change['proj']=row['projectKey']\n",
    "            _status_change['key']=row['key']\n",
    "            \n",
    "            # display(_status_change)\n",
    "            output_path = os.path.join(filepath, 'transition_history_Story_working.csv')\n",
    "            _status_change.to_csv(output_path ,mode='a', header=not os.path.exists(output_path), index=False)\n",
    "\n",
    "            \n",
    "    return l_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 15:20:35,653 - root - WARNING - processing 0            TEST\n",
      "1            CCEP\n",
      "2            CHAT\n",
      "3      COMPRODUCT\n",
      "4           AEMSC\n",
      "          ...    \n",
      "135           VMO\n",
      "136          WCDI\n",
      "137           WFM\n",
      "138          XSTR\n",
      "139           ZGA\n",
      "Name: key, Length: 138, dtype: object - Portfolio Initiative\n",
      "2024-12-24 15:20:39,395 - root - WARNING - renaming Portfolio Initiative_working.csv TO Portfolio Initiative.csv....\n",
      "2024-12-24 15:20:39,398 - root - WARNING - processing 0            TEST\n",
      "1            CCEP\n",
      "2            CHAT\n",
      "3      COMPRODUCT\n",
      "4           AEMSC\n",
      "          ...    \n",
      "135           VMO\n",
      "136          WCDI\n",
      "137           WFM\n",
      "138          XSTR\n",
      "139           ZGA\n",
      "Name: key, Length: 138, dtype: object - Product Initiative\n",
      "2024-12-24 15:20:41,186 - root - WARNING - renaming Product Initiative_working.csv TO Product Initiative.csv....\n",
      "2024-12-24 15:20:41,188 - root - WARNING - processing 0           TEST\n",
      "1           CCEP\n",
      "2           CHAT\n",
      "3     COMPRODUCT\n",
      "4          AEMSC\n",
      "5           AWFM\n",
      "6           AII2\n",
      "7             AT\n",
      "8             AU\n",
      "9            BAE\n",
      "10           BOT\n",
      "11         BRWSE\n",
      "12          CHSC\n",
      "13           CNC\n",
      "14            CE\n",
      "15         CPENG\n",
      "16          CCOE\n",
      "17           CSP\n",
      "18            CA\n",
      "19          CMST\n",
      "20         CROHR\n",
      "21         CROPS\n",
      "22        COBUSS\n",
      "23           CEA\n",
      "24           CCL\n",
      "25           CEO\n",
      "26          CSZI\n",
      "27          CXCD\n",
      "Name: key, dtype: object - Epic\n",
      "2024-12-24 15:20:54,666 - root - WARNING - processing 28       INTEL\n",
      "29      CLAIMS\n",
      "30         DNA\n",
      "31          DI\n",
      "32        DTIB\n",
      "33          DP\n",
      "34         DTD\n",
      "35       DCTEU\n",
      "36      DCTINT\n",
      "37       DCTOM\n",
      "38         DWP\n",
      "39        DAAS\n",
      "41         DPE\n",
      "42          DD\n",
      "43         DPT\n",
      "44         DWE\n",
      "45          DR\n",
      "46         DOM\n",
      "47      DOMSIT\n",
      "48      DOMUAT\n",
      "49         SII\n",
      "50    EADEVOPS\n",
      "51       EAFIN\n",
      "52         ESB\n",
      "53        EWFM\n",
      "55         EUS\n",
      "56         EVM\n",
      "57          EA\n",
      "Name: key, dtype: object - Epic\n",
      "2024-12-24 15:21:44,831 - root - WARNING - processing 58          ENT\n",
      "59         EUCF\n",
      "60    LOGISTICS\n",
      "61          EXV\n",
      "62         FEQA\n",
      "63          FIN\n",
      "64        FLDBA\n",
      "65        FLINV\n",
      "66        FLAIR\n",
      "67        FLAPI\n",
      "68        FLXFR\n",
      "69        FLXME\n",
      "70         FLXP\n",
      "71          FED\n",
      "72         GCPM\n",
      "73       AUTOPS\n",
      "74      DATAOPS\n",
      "75       INTOPS\n",
      "76       GOBEIP\n",
      "77         ICOE\n",
      "78           IL\n",
      "79          INV\n",
      "80         IPCM\n",
      "81         AUTO\n",
      "82         RESO\n",
      "83      MARTECH\n",
      "84         HAPS\n",
      "85           MA\n",
      "Name: key, dtype: object - Epic\n",
      "2024-12-24 15:22:01,984 - root - WARNING - processing 86      MEMBR\n",
      "87        QAS\n",
      "88      MERCH\n",
      "89      M365G\n",
      "90        MAD\n",
      "91      MAVEN\n",
      "92         NS\n",
      "93     OEPORT\n",
      "94       FLXO\n",
      "95      PAYAC\n",
      "96        PTF\n",
      "97         PT\n",
      "98        PIM\n",
      "99        PCR\n",
      "100        PE\n",
      "101      PPCL\n",
      "102       PWG\n",
      "103      PPUR\n",
      "104      PTAG\n",
      "105       PAI\n",
      "106       PAE\n",
      "107       PNC\n",
      "108       PDI\n",
      "109      CIAM\n",
      "110    LKSIDE\n",
      "111       ROI\n",
      "112    RTVREG\n",
      "Name: key, dtype: object - Epic\n",
      "2024-12-24 15:22:19,590 - root - WARNING - processing 113       SCHED\n",
      "114         SND\n",
      "115         SNB\n",
      "116       ITSEC\n",
      "117       SECSE\n",
      "118      SERNOW\n",
      "119         SHP\n",
      "120          SO\n",
      "121         SAM\n",
      "122     SOLEFIN\n",
      "123    SOLMERCH\n",
      "124         SSP\n",
      "125         SSE\n",
      "126    PRODSUPP\n",
      "127         SCM\n",
      "128        SPIM\n",
      "129        TECH\n",
      "130        TPCR\n",
      "131        TPDI\n",
      "132       WHSYS\n",
      "133         UXD\n",
      "134         VDI\n",
      "135         VMO\n",
      "136        WCDI\n",
      "137         WFM\n",
      "138        XSTR\n",
      "139         ZGA\n",
      "Name: key, dtype: object - Epic\n",
      "2024-12-24 15:23:04,165 - root - WARNING - renaming Epic_working.csv TO Epic.csv....\n",
      "2024-12-24 15:23:04,169 - root - WARNING - processing 0           TEST\n",
      "1           CCEP\n",
      "2           CHAT\n",
      "3     COMPRODUCT\n",
      "4          AEMSC\n",
      "5           AWFM\n",
      "6           AII2\n",
      "7             AT\n",
      "8             AU\n",
      "9            BAE\n",
      "10           BOT\n",
      "11         BRWSE\n",
      "12          CHSC\n",
      "13           CNC\n",
      "14            CE\n",
      "15         CPENG\n",
      "16          CCOE\n",
      "17           CSP\n",
      "18            CA\n",
      "19          CMST\n",
      "20         CROHR\n",
      "21         CROPS\n",
      "22        COBUSS\n",
      "23           CEA\n",
      "24           CCL\n",
      "25           CEO\n",
      "26          CSZI\n",
      "27          CXCD\n",
      "Name: key, dtype: object - Story\n",
      "2024-12-24 15:24:55,294 - root - WARNING - processing 28       INTEL\n",
      "29      CLAIMS\n",
      "30         DNA\n",
      "31          DI\n",
      "32        DTIB\n",
      "33          DP\n",
      "34         DTD\n",
      "35       DCTEU\n",
      "36      DCTINT\n",
      "37       DCTOM\n",
      "38         DWP\n",
      "39        DAAS\n",
      "41         DPE\n",
      "42          DD\n",
      "43         DPT\n",
      "44         DWE\n",
      "45          DR\n",
      "46         DOM\n",
      "47      DOMSIT\n",
      "48      DOMUAT\n",
      "49         SII\n",
      "50    EADEVOPS\n",
      "51       EAFIN\n",
      "52         ESB\n",
      "53        EWFM\n",
      "55         EUS\n",
      "56         EVM\n",
      "57          EA\n",
      "Name: key, dtype: object - Story\n",
      "2024-12-24 15:29:06,341 - root - WARNING - processing 58          ENT\n",
      "59         EUCF\n",
      "60    LOGISTICS\n",
      "61          EXV\n",
      "62         FEQA\n",
      "63          FIN\n",
      "64        FLDBA\n",
      "65        FLINV\n",
      "66        FLAIR\n",
      "67        FLAPI\n",
      "68        FLXFR\n",
      "69        FLXME\n",
      "70         FLXP\n",
      "71          FED\n",
      "72         GCPM\n",
      "73       AUTOPS\n",
      "74      DATAOPS\n",
      "75       INTOPS\n",
      "76       GOBEIP\n",
      "77         ICOE\n",
      "78           IL\n",
      "79          INV\n",
      "80         IPCM\n",
      "81         AUTO\n",
      "82         RESO\n",
      "83      MARTECH\n",
      "84         HAPS\n",
      "85           MA\n",
      "Name: key, dtype: object - Story\n",
      "2024-12-24 15:32:48,201 - root - WARNING - processing 86      MEMBR\n",
      "87        QAS\n",
      "88      MERCH\n",
      "89      M365G\n",
      "90        MAD\n",
      "91      MAVEN\n",
      "92         NS\n",
      "93     OEPORT\n",
      "94       FLXO\n",
      "95      PAYAC\n",
      "96        PTF\n",
      "97         PT\n",
      "98        PIM\n",
      "99        PCR\n",
      "100        PE\n",
      "101      PPCL\n",
      "102       PWG\n",
      "103      PPUR\n",
      "104      PTAG\n",
      "105       PAI\n",
      "106       PAE\n",
      "107       PNC\n",
      "108       PDI\n",
      "109      CIAM\n",
      "110    LKSIDE\n",
      "111       ROI\n",
      "112    RTVREG\n",
      "Name: key, dtype: object - Story\n",
      "2024-12-24 15:36:20,136 - root - WARNING - processing 113       SCHED\n",
      "114         SND\n",
      "115         SNB\n",
      "116       ITSEC\n",
      "117       SECSE\n",
      "118      SERNOW\n",
      "119         SHP\n",
      "120          SO\n",
      "121         SAM\n",
      "122     SOLEFIN\n",
      "123    SOLMERCH\n",
      "124         SSP\n",
      "125         SSE\n",
      "126    PRODSUPP\n",
      "127         SCM\n",
      "128        SPIM\n",
      "129        TECH\n",
      "130        TPCR\n",
      "131        TPDI\n",
      "132       WHSYS\n",
      "133         UXD\n",
      "134         VDI\n",
      "135         VMO\n",
      "136        WCDI\n",
      "137         WFM\n",
      "138        XSTR\n",
      "139         ZGA\n",
      "Name: key, dtype: object - Story\n",
      "2024-12-24 15:43:55,574 - root - WARNING - renaming Story_working.csv TO Story.csv....\n",
      "2024-12-24 15:43:55,575 - root - WARNING - Script ended accumulating data from JIRA \n",
      "2024-12-24 15:43:55,576 - root - WARNING - =======================================\n"
     ]
    }
   ],
   "source": [
    "# Get all .csv files in the 'data' directory\n",
    "csv_files = Path(filepath).glob(\"*_working.csv\")\n",
    "for file in csv_files:\n",
    "    filename=file.name\n",
    "    os.remove(os.path.join(filepath, filename))\n",
    "\n",
    "\n",
    "\n",
    "strings = projectList(api_token)\n",
    "\n",
    "for issueList in issueLists:\n",
    "    split_string_list = split_list(strings, issueList['partitionCnt'])\n",
    "    filtered_list = [series for series in split_string_list if not series.empty]\n",
    "    for partition in filtered_list:\n",
    "        logger.warning(f\"processing %s - %s\",partition,issueList['issueType'])\n",
    "\n",
    "        df=fetch(', '.join(['\"{}\"'.format(value) for value in partition]),issueList['issueType'])\n",
    "        if df is not None and not df.empty:\n",
    "            try:     \n",
    "                    output_path = os.path.join(filepath, f\"{issueList['issueType']}_working.csv\")            \n",
    "                    df.to_csv(output_path ,mode='a', header=not os.path.exists(output_path), index=False)\n",
    "            except Exception as e:  \n",
    "                logger.error(f\"Failed to upload files to {filepath}: {e}\")\n",
    "                pass\n",
    "                \n",
    "            logger.info(\"Move working files to current files\")\n",
    "            # Delete the old DataFrame \n",
    "            del(df)\n",
    "\n",
    "            # Perform garbage collection                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "            gc.collect()\n",
    "            # break\n",
    "    clean_folder(filepath,\"_working.csv\")\n",
    "logger.warning(f\"Script ended accumulating data from JIRA \")\n",
    "logger.warning(\"=======================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4 ('development')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fb6657aaf366e700473b4691a0218895a79fd82ea30347f6976080edd370586"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
