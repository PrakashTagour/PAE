{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./common.ipynb\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_token=os.getenv('JIRA_TOKEN')\n",
    "\n",
    "if not api_token:\n",
    "    raise ValueError(\"No JIRA API token found. Check your .env file / environment variable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run_proj = sys.argv[1]\n",
    "run_proj ='ALL'\n",
    "\n",
    "\n",
    "partitionCnt=5\n",
    "filepath='/Users/u1002018/Library/CloudStorage/OneDrive-SharedLibraries-FootLocker/Global Technology Services - DASH Doc Library/Timesheet/'\n",
    "\n",
    "# filepath='../output/TimeSheet'\n",
    "importfile='/Users/u1002018/Library/CloudStorage/OneDrive-SharedLibraries-FootLocker/Global Technology Services - DASH Doc Library/AllProjects/transition_history_Story.csv'\n",
    "\n",
    "issueLists = [\n",
    "            # {'issueType':\"Portfolio Initiative\",'partitionCnt':1},\n",
    "            # {'issueType':\"Product Initiative\", 'partitionCnt':1 },\n",
    "            # {'issueType':\"Epic\",'partitionCnt':partitionCnt},\n",
    "            {'issueType':\"Story\",'partitionCnt':partitionCnt}\n",
    "            ]\n",
    "             \n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jira ID \n",
    "# Name\n",
    "# Planview Portfolio ID\n",
    "# Work Description\n",
    "# IssueType\n",
    "# Work State\n",
    "def portoFolioDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.issuetype.name',\n",
    "                             'fields.status.name','fields.customfield_32307'\n",
    "                         #  'fields.description',\n",
    "        ]).rename(columns={\n",
    "        'key':'JiraID',\n",
    "        'fields.summary':'Name',\n",
    "        'fields.customfield_32307':'Planview Portfolio ID',\n",
    "        # 'fields.description':'Work Description',\n",
    "        'fields.issuetype.name':'IssueType',\n",
    "        'fields.status.name':'Work State'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name\n",
    "# ParentLink\n",
    "# Work Description\n",
    "# Jira ID\n",
    "# IssueType\n",
    "# Start date\n",
    "# End date\n",
    "# Work State\n",
    "def productInitDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.customfield_12823',\n",
    "                             'fields.issuetype.name','fields.status.name'\n",
    "                            #  'fields.description',\n",
    "                            ]).rename(columns={\n",
    "                            'key':'JiraID',\n",
    "                            'fields.summary':'Name',\n",
    "                            'fields.customfield_12823': 'ParentLink',\n",
    "                            # 'fields.description':'Work Description',\n",
    "                            'fields.issuetype.name':'IssueType',\n",
    "                            'fields.status.name':'Work State'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name ✅\n",
    "# ParentLink ✅\n",
    "# Work Description ❌\n",
    "# Jira ID ✅\n",
    "# IssueType ✅\n",
    "# Start date ✅\n",
    "# End date ✅\n",
    "# Banner ⏳ \n",
    "# Region ⏳\n",
    "# T-shirt Size ⏳\n",
    "# Epic Work Type ✅\n",
    "# Work State ✅\n",
    "# In-Progress DateDate ⏳\n",
    "# Completed Date ⏳\n",
    "def EpicDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.customfield_12823',\n",
    "                             'fields.issuetype.name','fields.status.name','fields.customfield_12305',\n",
    "                             'fields.customfield_31400', 'fields.customfield_13008', 'fields.customfield_12101',\n",
    "                            #  'fields.description',\n",
    "        ]).rename(columns={\n",
    "        'fields.summary':'Name',\n",
    "        'key':'JiraID',\n",
    "        'fields.customfield_12823': 'ParentLink',\n",
    "        'fields.customfield_13008': 'Targeted Start Date',\n",
    "        'fields.customfield_12101': 'Targeted End Date',\n",
    "        # 'fields.description':'Work Description',\n",
    "        'fields.customfield_12305':'Banner',\n",
    "        'fields.customfield_31400': 'Epic Type',\n",
    "        'fields.issuetype.name':'IssueType',\n",
    "        'fields.status.name':'Work State'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name ✅\n",
    "# ParentLink ✅\n",
    "# Work Description ❌\n",
    "# Jira ID ✅\n",
    "# IssueType ✅\n",
    "# Story Estimate ✅\n",
    "# Story Work Type ✅\n",
    "# Work State ✅\n",
    "# In-Progress Date ✅\n",
    "# Completed Date ✅\n",
    "# Jira Project Name ✅\n",
    "def StoryDataframe(dataframe):\n",
    "    return dataframe.filter(['key', 'fields.summary', 'fields.customfield_10006',\n",
    "                             'fields.customfield_10002',\n",
    "                             'fields.issuetype.name','fields.status.name',\n",
    "                             'fields.project.name','fields.customfield_31800'\n",
    "         #  'fields.description',\n",
    "        ]).rename(columns={\n",
    "        'fields.summary':'Name',\n",
    "        'fields.customfield_10006': 'ParentLink', #Epic Link\n",
    "      # 'fields.description':'Work Description',\n",
    "        'fields.customfield_31800':'story type',\n",
    "        'key':'JiraID',\n",
    "         'fields.issuetype.name':'IssueType',\n",
    "        'fields.customfield_10002':'StoryPoint',\n",
    "        'fields.status.name':'Work State',\n",
    "        'fields.project.name':'projectName'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "global logger\n",
    "logger = setup_logger()\n",
    "logger.info(\"=======================================\")\n",
    "logger.info(\"Script start accumulating data from JIRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDates(key,state):\n",
    "    dates=''\n",
    "    filterdata = importTransactionFile[importTransactionFile['key']==key]\n",
    "    if state == 'close':    \n",
    "     state= filterdata[filterdata['to'].isin(close_state)]\n",
    "    else:\n",
    "     state= filterdata[filterdata['to'].isin(development_state)]\n",
    "    \n",
    "    if state is not None and not state.empty:\n",
    "        dates= state['created_at'].values[0]\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(dataframe, issueType):\n",
    "    if dataframe is not None and not dataframe.empty:\n",
    "       if issueType == 'Portfolio Initiative':\n",
    "         dataframe = portoFolioDataframe(dataframe)\n",
    "       elif issueType == 'Product Initiative':\n",
    "         dataframe = productInitDataframe(dataframe)\n",
    "       elif issueType == 'Epic':\n",
    "          dataframe = EpicDataframe(dataframe)\n",
    "       elif issueType == 'Story':\n",
    "          dataframe = StoryDataframe(dataframe)\n",
    "          dataframe['In-Progress Date'] = dataframe['JiraID'].apply(lambda x: getDates(x,'inProgress'))\n",
    "          dataframe['Completed Date'] = dataframe['JiraID'].apply(lambda x: getDates(x,'close'))\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch( project, issueType):\n",
    "    global fetch_df \n",
    "    logger.info(f\"Fetch {issueType}...\")\n",
    "\n",
    "    # if issueType == 'Story':\n",
    "    #     attribute =' &expand=projects.issuetypes.fields,changelog'\n",
    "    # else:\n",
    "    attribute =' '\n",
    "\n",
    "    searchQry=f'?jql= project in ({project}) and issueType=\"{issueType}\" and updated > startOfMonth(-11)'\n",
    "\n",
    "    # if cond_flg == True: \n",
    "    #     searchQry=f\"{searchQry} and status not in (Cancelled, Done)  {attribute}\"\n",
    "    # else:\n",
    "    searchQry=f\"{searchQry} {attribute}\"\n",
    "\n",
    "    fetch_df = getDataSet(searchQry, project, issueType, api_token )\n",
    "\n",
    "    return data_clean(fetch_df,issueType )    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChangeLog(element):\n",
    "    changelog_Rec = [] \n",
    "    for history in element:\n",
    "        created_at = history.get('created',None)\n",
    "        for item in history['items']:\n",
    "            if item['field'] =='status' :\n",
    "                changelog_Rec.append({\n",
    "                    'created_at': created_at,\n",
    "                    'field': item['field'],\n",
    "                    'from': item['fromString'],\n",
    "                    'to': item['toString'],\n",
    "                })\n",
    "    return changelog_Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 09:11:25,850 - root - WARNING - processing PCR - Story\n",
      "2024-12-31 09:11:47,997 - root - WARNING - renaming Story_working.csv TO Story.csv....\n",
      "2024-12-31 09:11:48,099 - root - WARNING - Script ended accumulating data from JIRA \n",
      "2024-12-31 09:11:48,100 - root - WARNING - =======================================\n"
     ]
    }
   ],
   "source": [
    "# Get all .csv files in the 'data' directory\n",
    "csv_files = Path(filepath).glob(\"*_working.csv\")\n",
    "for file in csv_files:\n",
    "    filename=file.name\n",
    "    os.remove(os.path.join(filepath, filename))\n",
    "\n",
    "global importTransactionFile \n",
    "importTransactionFile = pd.read_csv(importfile)\n",
    "\n",
    "strings =pd.Series([\"PCR\"])\n",
    "# strings = projectList(api_token)\n",
    "\n",
    "for issueList in issueLists:\n",
    "    split_string_list = split_list(strings, issueList['partitionCnt'])\n",
    "    filtered_list = [series for series in split_string_list if not series.empty]\n",
    "    for partition in filtered_list:\n",
    "        logger.warning(f\"processing %s - %s\",partition.values[0],issueList['issueType'])\n",
    "\n",
    "        df=fetch(', '.join(['\"{}\"'.format(value) for value in partition]),issueList['issueType'])\n",
    "        if df is not None and not df.empty:\n",
    "            try:     \n",
    "                    output_path = os.path.join(filepath, f\"{issueList['issueType']}_working.csv\")            \n",
    "                    df.to_csv(output_path ,mode='a', header=not os.path.exists(output_path), index=False)\n",
    "            except Exception as e:  \n",
    "                logger.error(f\"Failed to upload files to {filepath}: {e}\")\n",
    "                pass\n",
    "                \n",
    "            logger.info(\"Move working files to current files\")\n",
    "            # Delete the old DataFrame \n",
    "            del(df)\n",
    "\n",
    "            # Perform garbage collection                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "            gc.collect()\n",
    "            # break\n",
    "    clean_folder(filepath,\"_working.csv\")\n",
    "\n",
    "del(importTransactionFile)\n",
    "# Perform garbage collection                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "gc.collect()\n",
    "logger.warning(f\"Script ended accumulating data from JIRA \")\n",
    "logger.warning(\"=======================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4 ('development')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fb6657aaf366e700473b4691a0218895a79fd82ea30347f6976080edd370586"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
